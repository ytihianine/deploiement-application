#jinja2:variable_start_string:'<<' , variable_end_string:'>>'

# Default airflow repository -- overridden by all the specific images below
defaultAirflowRepository: apache/airflow

# Default airflow tag to deploy
defaultAirflowTag: "3.1.5"

# Default airflow digest. If specified, it takes precedence over tag
defaultAirflowDigest: ~

# Airflow version (Used to make some decisions based on Airflow Version being deployed)
airflowVersion: "3.1.5"

# Images
images:
  airflow:
    repository: ghcr.io/ytihianine/traitement-de-donnees
    tag: 3.1.7
    # Specifying digest takes precedence over tag.
    # digest:
    pullPolicy: Always

# Ingress configuration
ingress:
  # Configs for the Ingress of the API Server - Airflow 3+
  apiServer:
    # Enable API Server ingress resource
    enabled: << values_files.ingress.apiServer.enabled >>

    # The hostnames or hosts configuration for the API Server Ingress
    hosts:
{% for host in values_files.ingress.apiServer.hosts %}
      # The hostname for the web Ingress (templated)
    - name: << host.name >>
      # configs for web Ingress TLS
      tls:
        # Enable TLS termination for the web Ingress
        enabled: false
        # the name of a pre-created Secret containing a TLS private key and certificate
        secretName: ""
{% endfor %}

    # The Ingress Class for the API Server Ingress (used only with Kubernetes v1.19 and above)
    ingressClassName: "nginx"

  # Configs for the Ingress of the web Service - Airflow < 3
  web:
    # Enable web ingress resource
    enabled: false

  # Configs for the Ingress of the flower Service
  flower:
    # Enable web ingress resource
    enabled: false

  # Configs for the Ingress of the statsd Service
  statsd:
    # Enable web ingress resource
    enabled: false

  # Configs for the Ingress of the pgbouncer Service
  pgbouncer:
    # Enable web ingress resource
    enabled: false

# Environment variables for all airflow containers
env:
{% for env_var in values_files.env_vars %}
  - name: "<< env_var.name >>"
    value: "<< env_var.value >>"
{% endfor %}

# Airflow database & redis config
data:
  # Otherwise pass connection values in
  metadataConnection:
    user: << values_files.data.metadataConnection.user >>
    pass: << values_files.data.metadataConnection.pass >>
    protocol: << values_files.data.metadataConnection.protocol >>
    host: << values_files.data.metadataConnection.host >>
    port: << values_files.data.metadataConnection.port >>
    db: << values_files.data.metadataConnection.db >>


# Fernet key settings
# Note: fernetKey can only be set during install, not upgrade
fernetKey: << values_files.fernetKey >>

# Flask secret key for Airflow 3+ Api: `[api] secret_key` in airflow.cfg
apiSecretKey: << values_files.apiSecretKey >>

# Secret key used to encode and decode JWTs: `[api_auth] jwt_secret` in airflow.cfg
jwtSecret: << values_files.jwtSecret >>

# Flask secret key for Airflow <3 Webserver: `[webserver] secret_key` in airflow.cfg
webserverSecretKey: << values_files.webserverSecretKey >>

# Airflow webserver settings
webserver:
  enabled: false

  # Create initial user.
  defaultUser:
    enabled: << values_files.webserver.defaultUser.enabled >>
    role: << values_files.webserver.defaultUser.role >>
    username: << values_files.webserver.defaultUser.username >>
    email: << values_files.webserver.defaultUser.email >>
    firstName: << values_files.webserver.defaultUser.firstName >>
    lastName: << values_files.webserver.defaultUser.lastName >>
    password: << values_files.webserver.defaultUser.password >>

# Airflow Worker Config
workers:
  persistence:
    # Enable persistent volumes
    enabled: false
    # This policy determines whether PVCs should be deleted when StatefulSet is scaled down or removed.
    persistentVolumeClaimRetentionPolicy: ~
    # Volume size for triggerer StatefulSet
    size: 30Gi

# Airflow Triggerer Config
triggerer:
  persistence:
    # Enable persistent volumes
    enabled: false
    # This policy determines whether PVCs should be deleted when StatefulSet is scaled down or removed.
    persistentVolumeClaimRetentionPolicy: ~
    # Volume size for triggerer StatefulSet
    size: 10Gi

postgresql:
  enabled: false

# Configuration for the redis provisioned by the chart
redis:
  enabled: true
  terminationGracePeriodSeconds: 10

  persistence:
    # Enable persistent volumes
    enabled: false
    # Volume size for worker StatefulSet
    size: 1Gi
    # If using a custom storageClass, pass name ref to all statefulSets here
    storageClassName: "longhorn"

# Git sync
dags:
  # Where dags volume will be mounted. Works for both persistence and gitSync.
  # If not specified, dags mount path will be set to $AIRFLOW_HOME/dags
  mountPath: ~
  persistence:
    # Enable persistent volume for storing dags
    enabled: false

  gitSync:
    enabled: << values_files.dags.gitSync.enabled >>

    # git repo clone url
    # ssh example: git@github.com:apache/airflow.git
    # https example: https://github.com/apache/airflow.git
    repo: << values_files.dags.gitSync.repo >>
    branch: << values_files.dags.gitSync.branch >>
    rev: << values_files.dags.gitSync.rev >>
    # The git revision (branch, tag, or hash) to check out, v4 only
    ref: << values_files.dags.gitSync.ref >>
    depth: << values_files.dags.gitSync.depth >>
    # the number of consecutive failures allowed before aborting
    maxFailures: << values_files.dags.gitSync.maxFailures >>
    # subpath within the repo where dags are located
    # should be "" if dags are at repo root
    subPath: << values_files.dags.gitSync.subPath | default('') | tojson >>
    period: << values_files.dags.gitSync.period >>
    wait: ~
    # add variables from secret into gitSync containers, such proxy-config
    envFrom: ~
    # envFrom: |
    #   - secretRef:
    #       name: 'proxy-config'

logs:
  # Configuration for empty dir volume (if logs.persistence.enabled == false)
  # emptyDirConfig:
  #   sizeLimit: 1Gi
  #   medium: Memory

  persistence:
    # Enable persistent volume for storing logs
    enabled: false
