########################################
## CONFIG | Airflow Configs
########################################
airflow:
  ## if we use legacy 1.10 airflow commands
  ##
  legacyCommands: false

  image:
    tag: 2.10.5-python3.12

  ## if we create a Deployment to perpetually sync `airflow.users`
  usersUpdate: false

  ## a list of users to create
  ## - templates can ONLY be used in: `password`, `email`, `firstName`, `lastName`
  ## - templates used a bash-like syntax: ${MY_USERNAME}, $MY_USERNAME
  ## - templates are defined in `usersTemplates`
  ## - `role` can be a single role or a list of roles
  ##
  users:
    - username: admin
      password: admin
      role: Admin
      email: admin@example.com
      firstName: admin
      lastName: admin

  ## the airflow executor type to use
  ## - allowed values: "CeleryExecutor", "KubernetesExecutor", "CeleryKubernetesExecutor"
  ## - customize the "KubernetesExecutor" pod-template with `airflow.kubernetesPodTemplate.*`
  ##
  executor: CeleryExecutor

  ## the fernet encryption key (sets `AIRFLOW__CORE__FERNET_KEY`)
  ## - [WARNING] you must change this value to ensure the security of your airflow
  ## - set `AIRFLOW__CORE__FERNET_KEY` with `airflow.extraEnv` from a Secret to avoid storing this in your values
  ## - use this command to generate your own fernet key:
  ##   python -c "from cryptography.fernet import Fernet; FERNET_KEY = Fernet.generate_key().decode(); print(FERNET_KEY)"
  ##
  fernetKey: "your own fernetKey"

  ## the secret_key for flask (sets `AIRFLOW__WEBSERVER__SECRET_KEY`)
  ## - [WARNING] you must change this value to ensure the security of your airflow
  ## - set `AIRFLOW__WEBSERVER__SECRET_KEY` with `airflow.extraEnv` from a Secret to avoid storing this in your values
  ##
  webserverSecretKey: "your own web server secret key"

  # Configuration
  config:
    AIRFLOW__CELERY__WORKER_CONCURRENCY: 10
  #  PIP_TIMEOUT: 60
  #  PIP_INDEX_URL: https://<username>:<password>@nexus.pic.dgfip.finances.rie.gouv.fr/repository/pypi/simple/
  #  PIP_TRUSTED_HOST: nexus.pic.dgfip.finances.rie.gouv.fr

  # Exemple pour ajouter un package
  #extraPipPackages:
  #  - "openpyxl==3.1.4"

###################################
## COMPONENT | Airflow scheduler
###################################
scheduler:
  ## configs for the log-cleanup sidecar of the worker Pods
  ## - helps prevent excessive log buildup by regularly deleting old files
  ##
  logCleanup:
    ## if the log-cleanup sidecar is enabled
    ## - [WARNING] must be disabled if `logs.persistence.enabled` is `true`
    ##
    enabled: false

###################################
## COMPONENT | Airflow workers
###################################
workers:
  # the initial/minimum number of workers
  replicas: 2

  resources:
    requests:
      memory: "4Gi"

  podDisruptionBudget:
    enabled: false
    ## prevents losing more than 20% of current worker task slots in a voluntary disruption
    maxUnavailable: "20%"

  autoscaling:
    enabled: true
    maxReplicas: 4
    metrics:
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
  ## configs for the log-cleanup sidecar of the worker Pods
  ## - helps prevent excessive log buildup by regularly deleting old files
  ##
  logCleanup:
    ## if the log-cleanup sidecar is enabled
    ## - [WARNING] must be disabled if `logs.persistence.enabled` is `true`
    ##
    enabled: false

###################################
## CONFIG | Airflow Logs
###################################
logs:
  ## the airflow logs folder
  ##
  path: /opt/airflow/logs

  ## configs for the logs PVC
  ##
  persistence:
    ## if a persistent volume is mounted at `logs.path`
    ##
    enabled: true

    ## the size of PVC to request
    ##
    size: 20Gi

###################################
## COMPONENT | Flower
###################################
flower:
  ## if the airflow flower UI should be deployed
  enabled: false

###################################
## CONFIG | External databases
###################################
postgresql:
  ## to use the external db, the embedded one must be disabled
  enabled: false

externalDatabase:
  type: postgres

  host: host de votre database
  port: 5432

  ## the schema which will contain the airflow tables
  database: airflow_demo

  ## Kubernetes secret in your airflow namespace
  userSecret: "database-credentials"
  userSecretKey: "username"
  passwordSecret: "database-credentials"
  passwordSecretKey: "password"

  ## use this for any extra connection-string settings, e.g. ?sslmode=disable
  properties: ""

###################################
## CONFIG | Airflow DAGs
###################################
dags:
  gitSync:
    enabled: true
    repo: your github http url
    branch: main
    subPath: ""
    httpSecret: airflow-secret
    httpSecretUsernameKey: username
    httpSecretPasswordKey: password
    syncWait: 30

###################################
## CONFIG | Kubernetes Ingress
###################################
ingress:
  enabled: true
  web:
    enabled: true
    ingressClassName: nginx
    host: "<your-host>.lab.incubateur.finances.rie.gouv.fr"

createUserJob:
  useHelmHooks: false
  applyCustomEnv: false
migrateDatabaseJob:
  useHelmHooks: false
  applyCustomEnv: false
